{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "workinprogress.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andygoosh/samsung/blob/master/workinprogress.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_Mg8x0gASeS",
        "colab_type": "code",
        "outputId": "602d6da8-9964-40f1-c0d5-b985679f4c9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from pathlib import Path\n",
        "from google.colab import files, drive\n",
        "from collections import defaultdict\n",
        "\n",
        "import re\n",
        "import random as rn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import array, argmax, random, take\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Dropout, Dense, LSTM, GRU, Embedding, RepeatVector, TimeDistributed\n",
        "from keras.layers import Bidirectional as Bi\n",
        "from keras import optimizers\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "RS = 77\n",
        "rn.seed(RS)\n",
        "# tf.random.set_seed(RS)\n",
        "np.random.seed(RS)\n",
        "np.random.RandomState(RS)\n",
        "\n",
        "gpath = Path('/content/gdrive')\n",
        "drive.mount(str(gpath))\n",
        "data_file = gpath / 'My Drive/Samsung' / 'transcriptions'"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KByWPn1DbpS",
        "colab_type": "text"
      },
      "source": [
        "#### Let's look at the data in given file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNLzpBAGDgAI",
        "colab_type": "code",
        "outputId": "9757363f-9535-4fe0-982f-1fde58700b74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "with data_file.open() as f:  \n",
        "    print(list(f.readline()))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['а', 'у', 'к', 'ц', 'и', 'о', 'н', 'ы', ' ', 'н', 'а', ' ', 'д', 'е', 'ш', 'ё', 'в', 'о', 'е', ' ', 'ж', 'и', 'л', 'ь', 'ё', ' ', 'п', 'р', 'о', 'в', 'о', 'д', 'я', 'т', 'с', 'я', ' ', 'р', 'е', 'г', 'у', 'л', 'я', 'р', 'н', 'о', '\\t', '%', '%', ' ', 'a', ' ', 'u', ' ', 'k', ' ', 't', 's', ' ', 'y', ' ', 'o', '1', ' ', 'n', ' ', 'a', 'x', ' ', '#', ' ', 'n', ' ', 'a', 'x', \"'\", ' ', '_', ' ', 'd', \"'\", ' ', \"'\", 'i', ' ', 's', 'h', ' ', 'o', '1', ' ', 'v', ' ', 'a', 'x', \"'\", ' ', 'j', 'a', 'x', ' ', '#', ' ', 'z', 'h', ' ', 'y', \"'\", ' ', 'l', \"'\", ' ', 'j', \"'\", ' ', \"'\", 'o', '1', ' ', '#', ' ', 'p', ' ', 'r', ' ', 'a', ' ', 'v', ' ', 'o', \"'\", '1', ' ', 'd', \"'\", ' ', \"'\", 'a', 'x', ' ', 't', 's', ' ', 't', 's', ' ', 'a', 'x', \"'\", ' ', '#', ' ', 'r', \"'\", ' ', \"'\", 'i', 'x', ' ', 'g', ' ', 'u', \"'\", ' ', 'l', \"'\", ' ', \"'\", 'a', '1', ' ', 'r', ' ', 'n', ' ', 'a', ' ', '%', '%', '\\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xmvmq8NkDzzF",
        "colab_type": "text"
      },
      "source": [
        "#### Notice that:\n",
        "1. russian sentence is separated from transcript with '\\t'\n",
        "2. the begining and the end of transcript part are marked by '%%'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9inDldeBBz8",
        "colab_type": "text"
      },
      "source": [
        "### Let's read the data and split it into rus and trans"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze9lEBcZB4A_",
        "colab_type": "code",
        "outputId": "e248d811-e6af-4862-e9b4-640e27c84275",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "rus_trn = []\n",
        "with data_file.open() as f:  \n",
        "  for line in f: \n",
        "    rus, trn = line.split('\\t')\n",
        "    rus_trn.append([rus.strip(), trn.strip()])\n",
        "\n",
        "print(f'Number of sentences in corpus: {len(rus_trn)}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sentences in corpus: 50277\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjFV-XOHBN8o",
        "colab_type": "text"
      },
      "source": [
        "##### Let's look at some sentences\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaCdAWXfBS-H",
        "colab_type": "code",
        "outputId": "bf192abf-fea4-479e-f01a-b1c98cae20f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "a,b,c = np.random.choice(len(rus_trn), 3)\n",
        "\n",
        "print(rus_trn[a][0])\n",
        "print(rus_trn[a][1])\n",
        "print(rus_trn[b][0])\n",
        "print(rus_trn[b][1])\n",
        "print(rus_trn[c][0])\n",
        "print(rus_trn[c][1])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "веб-операторы обязаны ознакомить пользователя с политикой по сбору персональной информации\n",
            "%% v' 'e1 p a' p' 'i r a1 t ax r ax # a' b' 'a1 z ax n ax # a z n a k o'1 m' 'ix' t' # p o'1 l' z ax v ax' t' 'ix' l' 'ax # s _ p a' l' 'i'1 t' 'ix k ax' j' # p a _ z b o1 r ux' # p' 'ix r s a n a'1 l' n ax' j' # 'i n f a r m a1 ts ax' i %%\n",
            "цена мартовского контракта на нефть в торговой системе поднялась\n",
            "%% ts y n a1 # m a1 r t ax f s k ax v ax # k a n t r a1 k t ax # n a' _ n' 'e1 f t' # f _ t a r g o1 v ax' j' # s' 'i' s' t' 'e'1 m' 'ix # p ax' d' n' 'i l a'1 s' %%\n",
            "в августе прошлого года был достроен храм христа спасителя\n",
            "%% v _ a1 v g ux' s' t' 'ix # p r o1 sh l ax v ax # g o1 d ax # b y1 l # d a s t r o'1 jax n # h r a1 m # h r' 'i s t a1 # s p a' s' 'i'1 t' 'ix' l' 'a %%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrtVAlRiBYLc",
        "colab_type": "text"
      },
      "source": [
        "#### Notice that words in russian sentence are separated by space while words in transcript are separated:\n",
        "1. by '#' in general case\n",
        "2. by '_' in case of preposition\n",
        "3. by '%% %%' in case of punctuation signs (dash, coma, etc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaYfq4rSFVs6",
        "colab_type": "text"
      },
      "source": [
        "#### Let's see if we have dupliates in corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoPm3mehFfiN",
        "colab_type": "code",
        "outputId": "c658ea67-e0ca-491e-a7cf-3958b0235b54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "a = array(rus_trn)\n",
        "seen_rus = Counter(a[:,0])\n",
        "seen_trn = Counter(a[:,1])\n",
        "\n",
        "print(f'Unique rus sentences: {len(seen_rus)} out of {len(rus_trn)}')\n",
        "print(f'Unique trans sentences: {len(seen_trn)} out of {len(rus_trn)}')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique rus sentences: 3131 out of 50277\n",
            "Unique trans sentences: 3171 out of 50277\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c_7KSzLGs7v",
        "colab_type": "text"
      },
      "source": [
        "#### We have a lot of duplicates! Only 3131 unique sentenses out of 50K in corpus. Please also note that some russian sentences are transcribed into different transcriptions (will look into that later on)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjR7uun4HeJF",
        "colab_type": "code",
        "outputId": "3d832f69-ec99-44e3-ac65-f2c137ec8a3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "lens = [each[1] for each in seen_rus.items()]\n",
        "unq = np.unique(lens)\n",
        "qty = [lens.count(each) for each in unq]\n",
        "pd.DataFrame(qty, index=unq).plot.bar(title = 'Rus sentence repeat times', legend=False);"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAERCAYAAACXT3dwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2bIKlVbIAxi",
        "colab_type": "text"
      },
      "source": [
        "#### Most duplicated sentences repeat 12 times, max up to 203 times"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCi44KJRImmG",
        "colab_type": "text"
      },
      "source": [
        "### Let's read that data while splitting the tokens. We'll count the tokens in each sentence. If the count in rus and trans is different, we'll record it as anomaly\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fznr-0SJ9nU",
        "colab_type": "code",
        "outputId": "623f551e-bb28-43ac-a5ac-c85f8c527964",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "rus_l, trn_l, anomaly = [], [], []\n",
        "seen = defaultdict(list)\n",
        "chars = Counter()\n",
        "\n",
        "for j,i in enumerate(rus_trn):\n",
        "  rus = i[0].split()\n",
        "  trn = re.split('#|_|%% %%',i[1])\n",
        "\n",
        "  if i[0] not in seen:\n",
        "    if abs(len(rus) - len(trn)) != 0: \n",
        "      anomaly.append(j)\n",
        "      # print(j, ' ', i[0])\n",
        "      # print( i[1])\n",
        "    \n",
        "    else:\n",
        "      rus_l.append(len(rus))\n",
        "      trn_l.append(len(trn))\n",
        "\n",
        "    chars += Counter(i[0])\n",
        "\n",
        "  seen[i[0]].append(j)\n",
        "\n",
        "print(f'Anomalies: {len(anomaly)}')\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1,ncols=2,figsize=(12,4))\n",
        "pd.DataFrame({'Number of words in Rus sentence':rus_l}).hist(ax=ax1, bins = 30);\n",
        "pd.DataFrame({'Number of words in Trns sentence':trn_l}).hist(ax=ax2, bins = 30);"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Anomalies: 49\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsUAAAEICAYAAAC3VYnvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxTcio_yKSbh",
        "colab_type": "text"
      },
      "source": [
        "#### So we have 49 anomalies out of 3131 samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uV_cJH70KuSg",
        "colab_type": "text"
      },
      "source": [
        "### Let's see if we need to clean the data. First let's take a look at rus corpus alphabet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyV9anvZn187",
        "colab_type": "code",
        "outputId": "db75f6ad-0825-4931-c5f3-089cd886022e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "s = sorted(chars.items())\n",
        "pd.DataFrame(s, index=(e[0]+' ' for e in s)).plot.bar(figsize=(18,4), rot=0, title = 'Char frequencies', legend=False)\n",
        "print(f'Number of times \"-\" used: {chars[\"-\"]}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of times \"-\" used: 159\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABCEAAAEICAYAAABh6e6nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJIQQAAAAwCSEEAAAAMAkhBAAAADAJP4/AfWfTsPfcq0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1296x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83TZ18z9K8Qy",
        "colab_type": "text"
      },
      "source": [
        "#### Looks good! We neither have punctuations nor capital letters. The only case to check is '-' letter which is used 159 times"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEqkK_LRKLb-",
        "colab_type": "code",
        "outputId": "f332396a-0d0a-4800-ce47-de1d3c5fd91f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "seen = set()\n",
        "seen_dash = set()\n",
        "dash_words = []\n",
        "for rus,trn in rus_trn:\n",
        "  if rus not in seen:\n",
        "    if '-' in rus:\n",
        "      ru_words = rus.split()\n",
        "      for each in ru_words:\n",
        "        if '-' in each:\n",
        "          if each not in seen_dash:\n",
        "            seen_dash.add(each)\n",
        "            dash_words.append(each)\n",
        "  else:\n",
        "    seen.add(rus)\n",
        "  \n",
        "print(dash_words)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['анти-обледенитель', 'иридо-диагностика', 'дом-красавец', 'из-за', 'радио-сигналом', 'ноль-три', 'ноль-два', 'мало-обеспеченные', 'шкаф-купе', 'тех-осмотр', 'пресс-службе', 'авто-сервис', 'чуть-чуть', 'аудио-', 'какие-либо', 'де-факто', 'стерео-', 'царь-колокол', 'царь-пушка', 'гео-магнитного', 'электро-катастрофы', 'фигуристы-новобранцы', 'что-то', 'какое-либо', 'веб-операторы', 'воздушно-десантной', 'военно-морских', 'ветераны-афганцы', 'одного-единственного', 'природно-климатические', 'одном-двух', 'санкт-петербурге', 'стран-участниц', 'пять-шесть', 'по-своему', 'матч-реванш', 'словаря-справочника', 'штаб-квартире', 'чем-то', 'чего-то', 'экс-губернатора', 'российско-американский', 'северо-восточных', 'красно-белую', 'какой-нибудь', 'бело-жёлтый', 'карту-схему', 'юго-западный', 'радио-охранное', 'по-прежнему', 'каким-то', 'кино-картины', 'авто-трюки', 'пресс-конференции', 'генерал-прокурором', 'нью-йорке', 'медиа-группы', 'нью-йоркской', 'какие-то', 'санкт-петербурга', 'санкт-петербург', 'памятники-символы', 'премьер-министр', 'взлётно-посадочную', 'какого-нибудь', 'январе-феврале', 'птица-говорун', 'жучки-камнееды', 'школу-комплекс', 'художников-оформителей', 'какое-то', 'купли-продажи', 'каких-либо', 'генерал-лейтенант', 'карты-схемы', 'кому-нибудь', 'детям-инвалидам', 'как-то', 'золото-валютных', 'наконец-то', 'государственно-общественной', 'бизнес-сообщества', 'причинно-следственных', 'по-настоящему', 'юго-западного', 'премьер-министру', 'нью-йорк', 'пропан-бутановые', 'пресс-служба', 'физико-химическими', 'средне-взвешенный', 'интернет-сетью', 'экспресс-опрос', 'либерально-демократической', 'вице-премьер', 'пресс-конференция', 'военно-морского', 'по-другому', 'вице-спикера', 'радио-станции', 'конференц-зале', 'золото-валютные', 'фирм-членов', 'премьер-министром', 'химико-фармацевтической', 'весенне-полевых', 'пресс-секретарь', 'сирийско-израильский', 'юго-восток', 'сьерра-леонэ', 'южно-африканской', 'медиа-мостом', 'диско-марафон', 'видео-', 'две-три', 'экс-посол', 'военно-политического', 'компакт-диски', 'мини-электростанция', 'когда-нибудь', 'кто-то', 'веке-волкодаве', 'из-под', 'капитан-лейтенанта', 'просто-напросто', 'всё-таки', 'пресс-службы', 'южно-сахалинске', 'оперативно-следственная', 'армяно-российского', 'северо-западе']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VHh6JUCPGlb",
        "colab_type": "text"
      },
      "source": [
        "#### Okey, words with dash look fine, we'll consider dash as a normal letter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-xAjHqyjh3x",
        "colab_type": "text"
      },
      "source": [
        "### So in order to implement autocoder for transcript we'd need to keep special symbools in transcript such as \"\\_\" and \"%% %%\". So let's create a dictionary of sentences rus <-> trans. So let's recreate the dictionary so \"\\_\" and \"%% %%\" are marked with '#' and remove begin and end markers. Plus to that let's get rid of duplicates.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7827cG05JrMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip3 install transliterate\n",
        "# from transliterate import translit\n",
        "# translit('длавды дылпадыал лыдап', 'ru', reversed=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBgF1l93y39m",
        "colab_type": "code",
        "outputId": "7f38b1f8-85c3-43ce-c058-43524f7199b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "seen_rus = set()\n",
        "seen_trn = set()\n",
        "\n",
        "res, trn_l, rus_l = [], [], []\n",
        "for rus, trn in rus_trn:\n",
        "\n",
        "  if rus not in seen_rus or trn not in seen_trn:\n",
        "      seen_rus.add(rus)\n",
        "      seen_trn.add(trn)\n",
        "\n",
        "      # trn = trn.replace('%% %%', '%% %% #').replace('_', '_ #')[3:-3]\n",
        "      # rus_l.append( len(rus))\n",
        "      # trn_l.append( len(trn.split(' ')))\n",
        "      # res.append([rus, trn.split(' ')])\n",
        "\n",
        "      trn = trn.replace('%% %%', '%% %% #').replace('_', '_ #')[2:-2]\n",
        "      rus_l.append( len(rus.split()))\n",
        "      trn_l.append( len(trn.split('#')))\n",
        "      # res.append([rus.split(), ['<sos>'] + trn.split('#'), ['<sos>'] + trn.split('#')])\n",
        "      res.append([rus.split(), trn.split('#')])\n",
        "\n",
        "rus_trn_new = array(res)\n",
        "trn_length = max(trn_l)\n",
        "rus_length = max(rus_l)\n",
        "print(f'max len rus: {rus_length}, max len trn: {trn_length}')\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1,ncols=2,figsize=(12,4))\n",
        "pd.DataFrame({'Number of words in Rus sentence':rus_l}).hist(ax=ax1, bins = 30);\n",
        "pd.DataFrame({'Number of words in Trns sentence':trn_l}).hist(ax=ax2, bins = 30);"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max len rus: 15, max len trn: 15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsUAAAEICAYAAAC3VYnvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dfZhkdXnn//dHxgdklEHRDg7E8RdY\nXeNExVnF1ZhBgovgBvfa6JolCi5m1l3jmmSSMGYfxKzJTi6X9eEX10gkMkbjyJK4sqBGQmxYkgCC\nIqDEZYKjzMiDhgcdMerEe/+o7yw1Pd3T1T1VXdVz3q/r6qvP+Z5T33NX1+m777rrVHWqCkmSJKnL\nHjbuACRJkqRxsyiWJElS51kUS5IkqfMsiiVJktR5FsWSJEnqPItiSZIkdZ5F8TKR5MIkbxvTsZPk\nA0nuS3LdOGLoi6WSHLvA25yR5NOjikmSDoT5/f/FYn7XWFkUL1KS7UnuSXJY39jrkkyPMaxReSFw\nMnB0VT133MEsVFV9uKpespjbJjk3yQ+S7Epyf5K/TPL8Ycc4Kov5IyN1nfl9+Vhsfk/yey2v70ry\n/b48vyvJJ0cR66gl2ZFk/bjjWM4sig/MIcCbxh3EQiU5ZIE3eTKwvaq+M4p4ZpNkxVIdawAfraqV\nwJHAZ4D/MeZ4JI2e+X1EJiG/V9Xrq2ply+2/Tcvz7eulM/efhJg1ehbFB+btwK8mWTVzQ5I1rUu3\nom9sOsnr2vJZSf4iyTtaB/L2JP+4jd/RuhRnzpj2yCSXJ/l2kiuTPLlv7qe1bfcm+XKSV/ZtuzDJ\ne5N8Isl3gBNnifdJSS5pt9+W5Bfa+NnA+4Hnt2fQb53ltl9N8py2fEa73z++5/ZJ/mdbfmSSdyb5\nevt6Z5JHtm3r27Pcc5LcBXygjf9akjvb/v9qxnFPTfKl9vPYmeRXZ3uQ2s/06r71SvL6JLe1n/17\nkmS22/arqt3Ah4HVSZ4w29x98x+7wBiPbY/pA0m+meSjfdvme2zfk+Sydoxrk/xY23ZV2+0L7bH7\nF238ZUluzEOd75/om297kl9NclOL5aNJHtW3/fR2228l+Zskp7Txw5Nc0B6rnUnetog/ztIkMb/T\nnfw+y7zHtrlem+RrwKf7xl7T7s83kmzqu80JST7X8uPdSd4+x9xPbI/X/e0xuapv29FJPtbm/kqS\nN/Rte1uSjyT5UPu53JLk+LbtI8CTgE+2x/JX2vgLklzTjnVjkhf1zXd1krem93fg20k+leRxfdtf\n1G77QDtvX93GH5Xkv7Wxu5P89/T9nVjWqsqvRXwB24GfBv4EeFsbex0w3ZbXAAWs6LvNNPC6tnwW\nsBt4Lb2OxNuArwHvAR4JvAT4NrCy7X9hW39R2/4u4Oq27TDgjjbXCuDZwDeBp/fd9gHgBfSeCD1q\nlvtzFfDfgUcBzwK+Aby4L9ar9/Oz+CCwsS2fD/wN8G/6tv1yW/5N4BrgicATgL8E/nPbtr79PH6n\n3b9DgVOAu4FntPv4R+1nemy7zZ3AT7blI4Dj54hvr/jbHJcCq4Afbff1lDluey7wobb8CGBz+9mu\nmOtns8gYPwL8+z2PD/DCBTy2fws8t23/MLB1tlja+rOBe4Dn0TvvzqR3Lj+y77y+jl5yfRxwK/D6\ntu259M6jk1ucq4GntW0fA97X4n1im+Nfj/v31C+/FvOF+b3/tgdtfu+7zbm0PN83dmyb6wPAo1vM\ne8Z+r/0sjwe+BxzXbvNZ4Ofa8mOA581xvLcDvws8nN7flRe18YcBNwK/0caPpXcuntS2vw34LvBP\n6J1Xb59x33cA6/vWj6H39+GftLlPaefO49v2q4HbgOPaffzfPHS+PwXYBbyS3nl3JPCstu3/p5fz\njwAeC3xiz2O93L/sFB+4/wS8Ma1zuEBfqaoPVNXfAx+ldwL/ZlV9r6o+DXyf3i/FHpdV1VVV9T16\nBdTzkxwDvIzey18fqKrdVfV54I+BV/Td9uNV9RdV9cOq+rv+INocLwDOqaq/q6ob6XUPXjPg/bgS\n+Km2/JPAf+lb/6m2HeCMdv/uqapvAG8FXt03zw+Bt7T7/116v4wfqKpbqvfS3rkzjvsD4OlJHltV\n91XV5waMF2BzVd1fVV+jd0nEs/az7yuT3E8vGf0C8LPV6xoPYtAYf0DvZcwntcdgT+djkMf2Y1V1\nXT3Uyd7ffdkAvK+qrq2qv6+qLfSS+gl9+7y7qr5eVfcC/6tvvrOBP6iqy9t5tLOq/jrJFHAq8EtV\n9Z2qugd4B/CqwX5E0sQyvx/8+X0+b6mqB1vMe5zbfpafA74IPLMv5uOSPL6qvl1V184x5w/oNR5+\ntKq+X1V7OsXPBx5bVb/dxrcBF7B3Lr2yqv60nVd/OM99ew1wSdv/h1X1KeAL9IrjPS6oqtuq6kF6\nlwbume/ngU9W1UXtvPtmVd2Y5GH0/g7+UntcvkXvnDgo8r1F8QGqqlvoPSvdNN++s7i7b/m7bb6Z\nYyv71u/oO+4u4F56v1hPBp7XXh65vxVwZwA/MtttZ/Ek4N6q+nbf2FfpdQIHcSXwk0mOovfs9SLg\nBUnWAIfTe+a75zhfnXGMJ/Wtf2NGQn/SjLj7bwvwz+kVY19N7+XGhbwB7q6+5QfZ++c800VVtQqY\nAm4BnrOA4wwa468DAa5L8sW+lxIHeWwXcl+eDGycMd8x7P04zDXfMfS6RLPN+XDgzr4530evYyQt\nW+Z34ODP7/PZ52dbVXPN/1rg6cCXk1yX5NQ55txM7/5ekd5laL/Wxp8M/OiMx/rX2X++P4y5PRn4\nuRnzncCB5fsfodft/0LfnJdykOR7LxwfjrcAnwPO6xvb86aFRwPfasv9J/ZiHLNnIclKei9vf53e\nL+2VVXXyfm5b+9n2deBxSR7Tlzh/FNg5SFBVtS3Jg8Abgauq6lvpXTe2gd5LOz/sO86T6T2z3nOM\nr+8nxjvpu89t//7jfhY4PcnDgV+kl6z79x+qqvpmkg3A9Un+qKrupPc4P3rPPkl+ZMZtBoqxJdk9\n1/m9EPizdp3ZII/tQtwB/FZV/dYib/tjc4x/DzhyAR10abkwv3cgv8+lqvb3s52575eBV7Vu6iuA\nP05yxMzufeuu/jLwy0nWAp9J7+Pw7gBuq6p/uNhwZ6zfQa8b/28WMdcdwE/MMn43vVc5njrjSd5B\nwU7xELSXOD4K/Lu+sW/QSzo/n+SQ1vmbraBYiFOTvDDJI4D/DFxTVXfQe5b2D5K8OsnD29c/SjLQ\nL1ab4y+B/9IuoP8Jei+Vf2gBsV1JL3HteSltesY69K6b/Q9JnpDkSHovTe7vGBcBZyV5epJH0/vj\nBECSR6T3po/Dq+oH9P4w/XCuiYalJb0/pffsHXovRf14kme1Nxqcu5gYk7wiydFt9T56ye2HHOBj\nSy+B/X99678PvD7J89JzWJLTkjxmgLkuAF6b5KQkD0uyOsnT2pODTwPnJXls2/ZjSX5qnvmkiWd+\nBzqS3w9Ue4yObE8UHuChPD5zv3/acmTafn/f9vsr4PtJNrbH6pAka9Pe6DiAmfn+D4F/luTkNtej\nkpyY5Elz3L7fh4BTkvzzJCuSHJnkme2yjfcD72yPddJ7c+CiPvZ00lgUD89vsu/LGL8A/Bq9C91/\nnF5iOhB/RC9x3EvvJfyfB2jP/l9C75qer9N7OWTPGxoG9XP03jzydXoX0L+lqv5sAbe/kt4bC66a\nYx16bxK4HrgJuJle92XOD6yvqk8C7wT+HNjWvvd7NbA9ybeA19N7SXEpvB3YkOSJVfV/6D32f0bv\nDQtXz9h30Bj/EXBtkl3AJcCbqur2ITy25wJb2stcr6yq6+mdl79Lr/jeRu+NKvOqquvovTz4DnqJ\n/Ep6nSHoXbv2COBLbd6LgaMGjFGadOb37uT3A3EqcGuSbwP/FfgXVfX9WfZ7Kr37uwv4C+BdVfW/\n2yttp9J7U/N2em+Kex+9N7MN4reBt7Z8/0tVtR34Z8B/pPeGw68BGxmg9quqrwD/FDiH3jn5OWBt\n27yR3uUf19H7W/Bpem/WW/aygFcGJEmSpIOSnWJJkiR1nkWxJEmSOs+iWJIkSZ1nUSxJkqTOm4jP\nKT7yyCNrzZo14w4DgO985zscdtj+Pgt7siy3eGH5xWy8ozVJ8d5www3frKrF/PcyDcBcv3jGO1rG\nO1qTFu9cuX4iiuI1a9Zw/fXXjzsMAKanp1m/fv24wxjYcosXll/MxjtakxRvkpn/VUtDZK5fPOMd\nLeMdrUmLd65c7+UTkiRJ6jyLYkmSJHWeRbEkSZI6z6JYkiRJnWdRLEmSpM6zKJYkSVLnWRRLkiSp\n8yyKJUmS1HkWxZIkSeq8ifiPdjp4rdl02T5jG9fu5qy+8e2bT1vKkCRJQzYz15vntRzZKZYkSVLn\nWRRLkiSp8yyKJUmS1HkWxZIkSeo8i2JJkiR1nkWxJEmSOs+iWJIkSZ1nUSxJkqTOsyiWJElS51kU\nS5IkqfMsiiVJktR5FsWSJEnqPItiSZIkdd5ARXGSVUkuTvLXSW5N8vwkj0tyeZLb2vcj2r5J8u4k\n25LclOT40d4FSZIk6cAM2il+F/Cpqnoa8EzgVmATcEVVHQdc0dYBXgoc1742AO8dasSSpKGz+SGp\n6+YtipMcDrwIuACgqr5fVfcDpwNb2m5bgJe35dOBD1bPNcCqJEcNPXJJ0jDZ/JDUaSsG2OcpwDeA\nDyR5JnAD8CZgqqrubPvcBUy15dXAHX2339HG7uwbI8kGesmUqakppqenF3kXhmvXrl0TE8sgJj3e\njWt37zM2deje45McP0z+z3gm49VC9TU/zoJe8wP4fpLTgfVtty3ANHAOfc0P4JrWZT6q72+CJC07\ngxTFK4DjgTdW1bVJ3sVD3QIAqqqS1EIOXFXnA+cDrFu3rtavX7+Qm4/M9PQ0kxLLICY93rM2XbbP\n2Ma1uznv5odOve1nrF/CiBZu0n/GMxmvFmEkzQ+wATIskx7vzAaIzY/RMt7RGKQo3gHsqKpr2/rF\n9Iriu/d0BtrlEfe07TuBY/puf3QbkyRNppE0P9rtbIAMwaTHO7MBYvNjtIx3NOa9priq7gLuSPLU\nNnQS8CXgEuDMNnYm8PG2fAnwmvZGjBOAB3xJTZIm2mzNj+NpzQ8Amx+SDnaDdIoB3gh8OMkjgNuB\n19IrqC9KcjbwVeCVbd9PAKcC24AH277SyK2Z5VKNfts3n7ZEkUjLS1XdleSOJE+tqi/zUPPjS/Sa\nHpvZt/nxi0m2As/D5oekg8BARXFV3Qism2XTSbPsW8AbDjAuTQCLTKlTbH5I6rRBO8WSpIOYzY9u\nmq/5AZPVAFlu8Wp58d88S5IkqfMsiiVJktR5FsWSJEnqPItiSZIkdZ5FsSRJkjrPoliSJEmdZ1Es\nSZKkzrMoliRJUudZFEuSJKnzLIolSZLUeRbFkiRJ6jyLYkmSJHWeRbEkSZI6z6JYkiRJnWdRLEmS\npM6zKJYkSVLnWRRLkiSp8yyKJUmS1HkWxZIkSeo8i2JJkiR1nkWxJEmSOs+iWJIkSZ03UFGcZHuS\nm5PcmOT6Nva4JJcnua19P6KNJ8m7k2xLclOS40d5ByRJkqQDtZBO8YlV9ayqWtfWNwFXVNVxwBVt\nHeClwHHtawPw3mEFK0kaDZsfkrruQC6fOB3Y0pa3AC/vG/9g9VwDrEpy1AEcR5K0NGx+SOqsFQPu\nV8CnkxTwvqo6H5iqqjvb9ruAqba8Grij77Y72tidfWMk2UAvmTI1NcX09PSi7sCw7dq1a2JiGcQo\n4924dvd+tw9y3NnmmDp07/FhxT+MeGfjOTFayy3ejjkdWN+WtwDTwDn0NT+Aa5KsSnJU398ESVp2\n0stp8+yUrK6qnUmeCFwOvBG4pKpW9e1zX1UdkeRSYHNVXd3GrwDOqarr55p/3bp1df31c25eUtPT\n06xfv37cYQxslPGu2XTZfrdv33zaoubYuHY359380POxQeYZxDDinY3nxGhNUrxJbujrknZKkq8A\n99Frgryvqs5Pcv+ePJ8kwH1VtWoheX5GA+Q5W7duXaJ7tH+7du1i5cqV4w5jYKOK9+adD8y7z9rV\nhy94nqlD4e7vLmyOQQwr3pk8H0Zr0uI98cQTZ831A3WKq2pn+35Pko8BzwXu3tMZaJdH3NN23wkc\n03fzo9uYJGlyvbC/+ZHkr/s3VlW1VwsXpL2yeD70GiCT8gRokp6MDWJU8Z41TzMBYPsZ8x935jz7\nND8GmGMQw4p3Js+H0Vou8c57TXGSw5I8Zs8y8BLgFuAS4My225nAx9vyJcBr2hsxTgAe8CU1SZps\n/c0PYK/mB4DND0kHu0HeaDcFXJ3kC8B1wGVV9SlgM3ByktuAn27rAJ8Abge2Ab8P/NuhRy1JGhqb\nH5I0wOUTVXU78MxZxv8WOGmW8QLeMJToJElLYQr4WO+yYVYAf1RVn0ryWeCiJGcDXwVe2fb/BHAq\nvebHg8Brlz5kSRquQT99QpJ0kLL5IUn+m2dJkiTJoliSJEmyKJYkSVLnWRRLkiSp8yyKJUmS1HkW\nxZIkSeo8i2JJkiR1nkWxJEmSOs+iWJIkSZ1nUSxJkqTOsyiWJElS51kUS5IkqfMsiiVJktR5FsWS\nJEnqPItiSZIkdZ5FsSRJkjrPoliSJEmdZ1EsSZKkzrMoliRJUudZFEuSJKnzLIolSZLUeQMXxUkO\nSfL5JJe29ackuTbJtiQfTfKINv7Itr6tbV8zmtAlSZKk4VhIp/hNwK19678DvKOqjgXuA85u42cD\n97Xxd7T9JEkTzuaHpC4bqChOcjRwGvD+th7gxcDFbZctwMvb8ultnbb9pLa/JGmy2fyQ1FkrBtzv\nncCvA49p648H7q+q3W19B7C6La8G7gCoqt1JHmj7f7N/wiQbgA0AU1NTTE9PL/IuDNeuXbsmJpZB\njDLejWt373f7IMedbY6pQ/ceH1b8w4h3Np4To7Xc4j1Y9TU/fgv4lb7mx79su2wBzgXeS6/5cW4b\nvxj43SSpqlrKmCVpmOYtipO8DLinqm5Isn5YB66q84HzAdatW1fr1w9t6gMyPT3NpMQyiFHGe9am\ny/a7ffsZ8x93tjk2rt3NeTc/dOoNMs8ghhHvbDwnRmu5xXsQG3rzA2yADMuo4p2vmQCLa4CMq/mx\n2GN5PozWcol3kE7xC4CfSXIq8CjgscC7gFVJVrSEeTSws+2/EzgG2JFkBXA48LdDj1ySNBSjan6A\nDZDFWjPjSf7GtX/PeVd/5/+tb9982lCOM18zARbXABlX82Oxx5r082Em4x2NeYviqnoz8GaAlix/\ntarOSPI/gJ8FtgJnAh9vN7mkrf9V2/7nvqQ2PPsmyt37JIlhJUtJnWHzQ1LnHcjnFJ9D77qzbfRe\nNrugjV8APL6N/wqw6cBClCSNUlW9uaqOrqo1wKvoNTPOAD5Dr7kBszc/wOaHpIPEoG+0A6CqpoHp\ntnw78NxZ9vk74BVDiE2SNF7nAFuTvA34PHs3P/6wNT/upVdIS9KytqCiWJJ0cLP5Iamr/DfPkiRJ\n6jyLYkmSJHWeRbEkSZI6z2uKpT4zP/IO9v3YOz/yTpKWNz/eVLOxUyxJkqTOsyiWJElS51kUS5Ik\nqfMsiiVJktR5FsWSJEnqPItiSZIkdZ5FsSRJkjrPoliSJEmdZ1EsSZKkzrMoliRJUudZFEuSJKnz\nLIolSZLUeRbFkiRJ6jyLYkmSJHWeRbEkSZI6z6JYkiRJnWdRLEmSpM6zKJYkSVLnzVsUJ3lUkuuS\nfCHJF5O8tY0/Jcm1SbYl+WiSR7TxR7b1bW37mtHeBUnSgTLXS+q6QTrF3wNeXFXPBJ4FnJLkBOB3\ngHdU1bHAfcDZbf+zgfva+DvafpKkyWaul9Rp8xbF1bOrrT68fRXwYuDiNr4FeHlbPr2t07aflCRD\ni1iSNHTmekldt2KQnZIcAtwAHAu8B/gb4P6q2t122QGsbsurgTsAqmp3kgeAxwPfnDHnBmADwNTU\nFNPT0wd0R4Zl165dExPLbDau3b3X+tSh+44NK/6Z8840yHFmm2NmzF2Nd1Qm/RyeabnFezAbRa6X\npOUiVTX4zskq4GPAfwQubC+bkeQY4JNV9YwktwCnVNWOtu1vgOdV1ZyJct26dXX99dcfwN0Ynunp\nadavXz/uMOa0ZtNle61vXLub827e+7nN9s2njeRYMw1ynNnmmBlzV+MdlUk/h2eapHiT3FBV68Yd\nx7gNM9fPaIA8Z+vWrUt4T+a2a9cuVq5cOe4w5nTzzgf2Wp86FO7+7kPra1cfPpLjzGaQYx1s8Q46\nz7hM+vk706TFe+KJJ86a6wfqFO9RVfcn+QzwfGBVkhWtg3A0sLPtthM4BtiRZAVwOPC3BxS9JGnJ\nDDPXV9X5wPnQa4BMyhOgSXoyNpuz5mmAbD9j/UiOM5tBjnWwxTvoPOMy6efvTMsl3kE+feIJrWtA\nkkOBk4Fbgc8AP9t2OxP4eFu+pK3Ttv95LaQdLUlacuZ6SV03SKf4KGBLu9bsYcBFVXVpki8BW5O8\nDfg8cEHb/wLgD5NsA+4FXjWCuCVJw2Wul9Rp8xbFVXUT8OxZxm8HnjvL+N8BrxhKdJKkJWGul9R1\n/kc7SZIkdZ5FsSRJkjrPoliSJEmdZ1EsSZKkzrMoliRJUudZFEuSJKnzLIolSZLUeRbFkiRJ6jyL\nYkmSJHWeRbEkSZI6z6JYkiRJnWdRLEmSpM6zKJYkSVLnWRRLkiSp8yyKJUmS1HkWxZIkSeo8i2JJ\nkiR13opxByB11ZpNl827z/bNpy1BJJIkyaJYkiRpBGx+LC9ePiFJkqTOsyiWJElS51kUS5IkqfPm\nLYqTHJPkM0m+lOSLSd7Uxh+X5PIkt7XvR7TxJHl3km1Jbkpy/KjvhCRJknQgBukU7wY2VtXTgROA\nNyR5OrAJuKKqjgOuaOsALwWOa18bgPcOPWpJ0tDY/JCkAYriqrqzqj7Xlr8N3AqsBk4HtrTdtgAv\nb8unAx+snmuAVUmOGnrkkqRhsfkhqfMWdE1xkjXAs4FrgamqurNtuguYasurgTv6brajjUmSJpDN\nD0mCVNVgOyYrgSuB36qqP0lyf1Wt6tt+X1UdkeRSYHNVXd3GrwDOqarrZ8y3gV6Hgampqeds3bp1\nOPfoAO3atYuVK1eOO4w53bzzgb3Wpw6Fu7+79z5rVx8+kmPNNMhxZptjZszGO7fFHGvSz+GZJine\nE0888YaqWjfuOMapNT+uAp4BfG1Pnk8S4L6qWjVonm/bzPWLMF+un7Q8dLDFO+g8Cz3ObMzzS2+u\nXD/QP+9I8nDgj4EPV9WftOG7kxxVVXe2DsE9bXwncEzfzY9uY3upqvOB8wHWrVtX69evH/S+jNT0\n9DSTEstszprxQeAb1+7mvJv3fhi3n7F+JMeaaZDjzDbHzJiNd26LOdakn8MzLbd4D2at+fHHwC9V\n1bd6dXBPVVWSwboofcz1izNfrp+0PHSwxTvoPAs9zmzM85NjkE+fCHABcGtV/be+TZcAZ7blM4GP\n942/pr0R4wTggb7LLCRJE2h/zY+2fcHND0laTga5pvgFwKuBFye5sX2dCmwGTk5yG/DTbR3gE8Dt\nwDbg94F/O/ywJUnDYvNDkga4fKJdM5Y5Np80y/4FvOEA45IkLZ09zY+bk9zYxn6DXrPjoiRnA18F\nXtm2fQI4lV7z40HgtUsbriQN30DXFEuSDl42PyTJf/MsSZIkWRRLkiRJXj6xRNYM8rEsm09bgkgk\nSaNirpeWLzvFkiRJ6jyLYkmSJHWeRbEkSZI6z6JYkiRJnWdRLEmSpM6zKJYkSVLnWRRLkiSp8yyK\nJUmS1HkWxZIkSeo8i2JJkiR1nkWxJEmSOs+iWJIkSZ1nUSxJkqTOsyiWJElS51kUS5IkqfMsiiVJ\nktR5FsWSJEnqPItiSZIkdZ5FsSRJkjpv3qI4yR8kuSfJLX1jj0tyeZLb2vcj2niSvDvJtiQ3JTl+\nlMFLkobDXC+p6wbpFF8InDJjbBNwRVUdB1zR1gFeChzXvjYA7x1OmJKkEbsQc72kDpu3KK6qq4B7\nZwyfDmxpy1uAl/eNf7B6rgFWJTlqWMFKkkbDXC+p61JV8++UrAEurapntPX7q2pVWw5wX1WtSnIp\nsLmqrm7brgDOqarrZ5lzA70OA1NTU8/ZunXrcO7RAdq1axcrV64c+rw373xg3n3Wrj58wfNMHQp3\nf3fh8wxivpgXEy/sG7Pxzm2+Yy1lvKMyqt+5xTjxxBNvqKp1445jXMz1B26pcv0k5aHZ5lnu8Q46\nz0KPM5vFHGeS8uYgJi3euXL9igOduKoqyfyV9b63Ox84H2DdunW1fv36Aw1lKKanpxlFLGdtumze\nfbafMf9xZ86zce1uzrt574dxkHkGMV/Mi4kX9o3ZeOc237GWMt5RGdXvnIbLXD+Ypcr1k5SHZptn\nucc76DwLPc5sFnOc5ZY3l0u8iy2K705yVFXd2V4yu6eN7wSO6dvv6DYmSVp+zPXSBFgzSxE/s+De\nvvm0pQzpoLTYj2S7BDizLZ8JfLxv/DXtncknAA9U1Z0HGKMkaTzM9ZI6Y95OcZKPAOuBI5PsAN4C\nbAYuSnI28FXglW33TwCnAtuAB4HXjiBmSdKQmesldd28RXFV/dwcm06aZd8C3nCgQUmSlpa5XlLX\n+R/tJEmS1HkWxZIkSeo8i2JJkiR1nkWxJEmSOs+iWJIkSZ1nUSxJkqTOsyiWJElS51kUS5IkqfMs\niiVJktR5FsWSJEnqPItiSZIkdZ5FsSRJkjrPoliSJEmdZ1EsSZKkzrMoliRJUudZFEuSJKnzVow7\nAEnLw5pNl827z/bNpy1BJJKkUeh6nrdTLEmSpM7rfKd45rOijWt3c9aMsYP5WZEkHexm637NzPXm\neUl2iiVJktR5ne8US1pa8706Y8dOkpa35foqvJ1iSZIkdZ5FsSRJkjpvJEVxklOSfDnJtiSbRnEM\nSdJ4meslHUyGfk1xkkOA9wAnAzuAzya5pKq+NOxjSeqmrn+W5iQw10satfly/bDz/CjeaPdcYFtV\n3Q6QZCtwOjDUROkfRUkaK3O9pINKqmq4EyY/C5xSVa9r668GnldVvzhjvw3Ahrb6VODLQw1k8Y4E\nvjnuIBZgucULyy9m4x2tSYHT1ooAAAQ5SURBVIr3yVX1hHEHsRyY65ec8Y6W8Y7WpMU7a64f20ey\nVdX5wPnjOv5cklxfVevGHcegllu8sPxiNt7RWm7xamHM9cNhvKNlvKO1XOIdxRvtdgLH9K0f3cYk\nSQcPc72kg8ooiuLPAscleUqSRwCvAi4ZwXEkSeNjrpd0UBn65RNVtTvJLwJ/ChwC/EFVfXHYxxmh\niXuZbx7LLV5YfjEb72gtt3iFuX4MjHe0jHe0lkW8Q3+jnSRJkrTc+B/tJEmS1HkWxZIkSeo8i+IZ\nkhyS5PNJLh13LPNJsirJxUn+OsmtSZ4/7pj2J8kvJ/likluSfCTJo8Yd00xJ/iDJPUlu6Rt7XJLL\nk9zWvh8xzhj7zRHv29s5cVOSjyVZNc4Y+80Wb9+2jUkqyZHjiE3dsZzyPJjrh808P1rLOc9bFO/r\nTcCt4w5iQO8CPlVVTwOeyQTHnWQ18O+AdVX1DHpvzHnVeKOa1YXAKTPGNgFXVNVxwBVtfVJcyL7x\nXg48o6p+Avg/wJuXOqj9uJB94yXJMcBLgK8tdUDqpOWU58FcP2wXYp4fpQtZpnneorhPkqOB04D3\njzuW+SQ5HHgRcAFAVX2/qu4fb1TzWgEcmmQF8Gjg62OOZx9VdRVw74zh04EtbXkL8PIlDWo/Zou3\nqj5dVbvb6jX0Pj92Iszx8wV4B/DrgO/81UgtpzwP5vpRMM+P1nLO8xbFe3snvQfsh+MOZABPAb4B\nfKC9DPj+JIeNO6i5VNVO4L/Se4Z4J/BAVX16vFENbKqq7mzLdwFT4wxmgf4V8MlxB7E/SU4HdlbV\nF8YdizphOeV5MNcvFfP8CC2XPG9R3CR5GXBPVd0w7lgGtAI4HnhvVT0b+A6T9XLPXtr1WafTS/BP\nAg5L8vPjjWrhqvcZhhP7LLdfkn8P7AY+PO5Y5pLk0cBvAP9p3LHo4LcM8zyY65eceX64llOetyh+\nyAuAn0myHdgKvDjJh8Yb0n7tAHZU1bVt/WJ6iXNS/TTwlar6RlX9APgT4B+POaZB3Z3kKID2/Z4x\nxzOvJGcBLwPOqMn+MPIfo/fH8wvtd+9o4HNJfmSsUelgtdzyPJjrl4p5fnSWTZ63KG6q6s1VdXRV\nraH3poA/r6qJfXZbVXcBdyR5ahs6CfjSGEOaz9eAE5I8OknoxTuxbxaZ4RLgzLZ8JvDxMcYyrySn\n0Ht5+Geq6sFxx7M/VXVzVT2xqta0370dwPHt/JaGarnleTDXLyHz/IgspzxvUby8vRH4cJKbgGcB\nvz3meObUuhwXA58DbqZ37k3cv31M8hHgr4CnJtmR5GxgM3ByktvodUE2jzPGfnPE+7vAY4DLk9yY\n5PfGGmSfOeKVtH/m+iEyz4/Wcs7z/ptnSZIkdZ6dYkmSJHWeRbEkSZI6z6JYkiRJnWdRLEmSpM6z\nKJYkSVLnWRRLkiSp8yyKJUmS1Hn/Fy/uYO6nggUhAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ID8a8MoaKtVm",
        "colab_type": "code",
        "outputId": "6586faa3-a861-48c6-9031-fb913260e288",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "rus_trn_new[0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list(['аукционы', 'на', 'дешёвое', 'жильё', 'проводятся', 'регулярно']),\n",
              "       list(['<sos>', ' a u k ts y o1 n ax ', \" n ax' _ \", \" d' 'i sh o1 v ax' jax \", \" zh y' l' j' 'o1 \", \" p r a v o'1 d' 'ax ts ts ax' \", \" r' 'ix g u' l' 'a1 r n a \"])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbQ82gWtkTDx",
        "colab_type": "text"
      },
      "source": [
        "### Text to Sequence Conversion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nt-GGIUNlkCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenization(lines, split=' ', char_level=False):\n",
        "  tokenizer = Tokenizer(filters='', lower=False, split=split, char_level=char_level)\n",
        "  tokenizer.fit_on_texts(lines)\n",
        "  return tokenizer\n",
        "\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "  seq = tokenizer.texts_to_sequences(lines)\n",
        "  seq = pad_sequences(sequences=seq, maxlen=length, padding='post')\n",
        "  return seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "670W8CC1llqC",
        "colab_type": "code",
        "outputId": "a4d723b8-68bb-4d51-ad70-3b18e0597be0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "rus_tokenizer = tokenization(rus_trn_new[:, 0], split='',  char_level=True)\n",
        "rus_vocab_size = len(rus_tokenizer.word_index) + 1\n",
        "trn_tokenizer = tokenization(rus_trn_new[:, 1], split=' ', char_level=False)\n",
        "trn_vocab_size = len(trn_tokenizer.word_index) + 1\n",
        "print(f'Rus Vocabulary Size: {rus_vocab_size}')\n",
        "print(f'Trns Vocabulary Size: {trn_vocab_size}')\n",
        "a = np.random.choice(rus_vocab_size)\n",
        "print(trn_tokenizer.index_word[a])\n",
        "print(rus_tokenizer.index_word[a])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rus Vocabulary Size: 12176\n",
            "Trns Vocabulary Size: 13891\n",
            " u'1 l' 'ix' ch' n ax m \n",
            "реестра\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgJdhdjvqRA9",
        "colab_type": "text"
      },
      "source": [
        "### Model Building\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaO755OI17PU",
        "colab_type": "code",
        "outputId": "650c8020-efe4-4213-e45e-942a1f7477a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "rus_trn_new.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3172, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XcT-AUGqa5v",
        "colab_type": "code",
        "outputId": "0735962b-434a-45f9-c2b0-755ab27d7fd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train, test = train_test_split(rus_trn_new, test_size=0.01, random_state = RS)\n",
        "\n",
        "# prepare training data\n",
        "trainX = encode_sequences(rus_tokenizer, rus_length, train[:, 0])\n",
        "# trainX_ = encode_sequences(trn_tokenizer, trn_length, train[:, 2])\n",
        "trainY = encode_sequences(trn_tokenizer, trn_length, train[:, 1])\n",
        "\n",
        "# prepare validation data\n",
        "testX = encode_sequences(rus_tokenizer, rus_length, test[:, 0])\n",
        "# testX_ = encode_sequences(trn_tokenizer, trn_length, test[:, 2])\n",
        "testY = encode_sequences(trn_tokenizer, trn_length, test[:, 1])\n",
        "\n",
        "trainX.shape, testX.shape"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3140, 15), (32, 15))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGzWdS9cips_",
        "colab_type": "code",
        "outputId": "7809ec76-f6c0-468d-a338-cdf092450ed0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print(f'{t} ----> {lang.index_word[t]}')\n",
        "\n",
        "a = np.random.choice(len(trainX))\n",
        "convert(rus_tokenizer, trainX[a])\n",
        "print ()\n",
        "convert(trn_tokenizer, trainY[a])"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1825 ----> столичные\n",
            "4056 ----> автомобилисты\n",
            "544 ----> смогут\n",
            "4057 ----> проехаться\n",
            "155 ----> над\n",
            "4058 ----> площадью\n",
            "4059 ----> гагарина\n",
            "6 ----> по\n",
            "4060 ----> эстакаде\n",
            "\n",
            "1671 ---->  s t a' l' 'i'1 ch' n ax' jax \n",
            "4031 ---->  a1 f t ax m ax' b' 'i' l' 'i1 s t ax \n",
            "475 ---->  s m o1 g ux t \n",
            "4032 ---->  p r a' j' 'e1 h ax ts ts ax \n",
            "1672 ---->  n a t _ \n",
            "4033 ---->  p l o'1 sh' 'ax' d' j' 'ux \n",
            "4034 ---->  g a g a'1 r' 'ix n ax \n",
            "16 ---->  p ax _ \n",
            "4035 ---->  e s t a k a'1 d' 'e \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5FSiYilVXvv",
        "colab_type": "text"
      },
      "source": [
        "#### FastText"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8eeBkKPCPse",
        "colab_type": "code",
        "outputId": "910e9689-034e-4bcf-ec98-56440f22f26e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "from gensim.models.fasttext import FastText\n",
        "rus_model = FastText(size=20)\n",
        "trn_model = FastText(size=20)\n",
        "\n",
        "rus_model.build_vocab(sentences=rus_trn_new[:, 0])\n",
        "trn_model.build_vocab(sentences=rus_trn_new[:, 1])\n",
        "\n",
        "total_rus = rus_model.corpus_total_words\n",
        "total_trn = trn_model.corpus_total_words\n",
        "print(total_rus, total_trn)\n",
        "\n",
        "rus_model.train(sentences=rus_trn_new[:,0], total_examples = rus_model.corpus_count, epochs=rus_model.iter)\n",
        "trn_model.train(sentences=rus_trn_new[:,1], total_examples = trn_model.corpus_count, epochs=trn_model.iter)\n",
        "\n",
        "print(rus_model.wv['и'])\n",
        "print(trn_model.wv[\" i _ \"])\n",
        "\n",
        "rus_model.wv.similar_by_vector(trn_model.wv[\" i _\"])\n",
        "# trn_model.wv.similar_by_vector(rus_model.wv['группа'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32448 32395\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[-0.69065756  0.4192582  -1.2095522  -0.01563328 -0.5254309   0.5680641\n",
            " -0.65832     0.16494563 -0.406429    0.3612038  -1.1729337   0.1500966\n",
            "  0.4335361  -0.03284142 -0.88770705  0.15605743  0.08337434 -0.57792157\n",
            " -1.086083    0.5548296 ]\n",
            "[ 0.56364745  0.70111406 -0.36694923  0.05703797 -0.52206254  0.79194874\n",
            " -1.2288195  -0.7276088   0.29206008  0.5571377  -0.46059236  0.7377961\n",
            " -0.00935896  1.1696087   1.1398089  -0.6379641  -0.2372518  -0.03386954\n",
            " -0.6044104   0.5300397 ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('я', 0.3086957335472107),\n",
              " ('ряд', 0.30652180314064026),\n",
              " ('им', 0.2938210964202881),\n",
              " ('даёт', 0.2934850752353668),\n",
              " ('кредит', 0.2921362817287445),\n",
              " ('фонд', 0.2906072735786438),\n",
              " ('чечни', 0.28800374269485474),\n",
              " ('вызывает', 0.28710639476776123),\n",
              " ('открытие', 0.28527945280075073),\n",
              " ('роль', 0.28502026200294495)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EovHsdWV0JJg",
        "colab_type": "code",
        "outputId": "3f49f479-aa94-4e4f-8912-cccefb9f63d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "trn_model.most_similar(' d' 'ix p u t a1 t ')\n",
        "# rus_model.most_similar('депутат')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(' i _ ', 0.9997418522834778),\n",
              " (\" b' 'u d zh e1 t \", 0.9996572136878967),\n",
              " (\" z' _ \", 0.9996542930603027),\n",
              " (\" n' 'e1 t \", 0.9996196031570435),\n",
              " (' e1 t ax ', 0.9996190071105957),\n",
              " (\" 'i _ \", 0.9996137619018555),\n",
              " (\" s' _ \", 0.9996098875999451),\n",
              " (\" d' 'e'1 n' \", 0.9996077418327332),\n",
              " (\" f s' 'e1 h \", 0.999605119228363),\n",
              " (\" sh' _ \", 0.9996048212051392)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pd8zTiADVilf",
        "colab_type": "text"
      },
      "source": [
        "### Moving on"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a9-aKMvp3OF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2f7f702d-345c-49a4-b1ba-7c0827f35095"
      },
      "source": [
        "trainY[17]"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5749,  104, 5750, 5751, 5752,  660, 5753,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwOy43R15_yn",
        "colab_type": "code",
        "outputId": "5a4a36c9-b51e-4c05-eec7-d963918de174",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "BS = 128\n",
        "EPOCHES = 500\n",
        "\n",
        "def define_model(in_vocab, out_vocab, in_timesteps, out_timesteps, units):\n",
        "  input = x = Input(shape=(None,))\n",
        "  x = Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True)(x)\n",
        "  x, h, c = LSTM(units, return_state=True)(x)\n",
        "  x = RepeatVector(out_timesteps)(x)\n",
        "  x = LSTM(units, return_sequences=True)(x, initial_state = (h, c))\n",
        "  output = TimeDistributed(Dense(out_vocab, activation='softmax'))(x)\n",
        "  inference_model = model = Model(input, output)\n",
        "  return model, inference_model\n",
        "\n",
        "def define_model1(in_vocab, out_vocab, in_timesteps, out_timesteps, units):\n",
        "   # encoder\n",
        "  encoder_inputs = Input(shape=(None,))\n",
        "  encoder_embedding = Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True)\n",
        "  encoder = encoder_embedding(encoder_inputs)\n",
        "  _, state_h, state_c = LSTM(units, return_state=True)(encoder)\n",
        "  encoder_states = [state_h, state_c]\n",
        "  # decoder\n",
        "  decoder_inputs = Input(shape=(None,))\n",
        "  decoder_embedding = Embedding(out_vocab, units, input_length=out_timesteps, mask_zero=True)\n",
        "  decoder = decoder_embedding(decoder_inputs)\n",
        "  decoder_lstm = LSTM(units, return_sequences=True, return_state=True)\n",
        "  decoder_outputs, _, _ = decoder_lstm(decoder, initial_state=encoder_states)\n",
        "  decoder_dense = Dense(out_vocab, activation='softmax')\n",
        "  decoder_outputs = decoder_dense(decoder_outputs)\n",
        "  model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "  #inference model\n",
        "  encoder_model = Model(encoder_inputs, encoder_states)\n",
        "  decoder_state_input_h = Input(shape=(units,))\n",
        "  decoder_state_input_c = Input(shape=(units,))\n",
        "  decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "  decoder_inputs_single = Input(shape=(None,))\n",
        "  decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\n",
        "  decoder_outputs, h, c = decoder_lstm(decoder_inputs_single_x, initial_state=decoder_states_inputs)\n",
        "  decoder_states = [h, c]\n",
        "  decoder_outputs = decoder_dense(decoder_outputs)\n",
        "  inference_model = Model(\n",
        "      [decoder_inputs_single] + decoder_states_inputs,\n",
        "      [decoder_outputs] + decoder_states\n",
        "  )\n",
        "  return model, inference_model\n",
        "\n",
        "model, model_inf = define_model(rus_vocab_size, trn_vocab_size, rus_length, trn_length, 128)\n",
        "model.summary()\n",
        "\n",
        "# optimizer = optimizers.RMSprop(lr=0.001)\n",
        "optimizer=optimizers.Adam()\n",
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy')\n",
        "\n",
        "monitor = 'val_loss'\n",
        "mode = 'min'\n",
        "filename = 'model.h5'\n",
        "checkpoint = ModelCheckpoint(filename, monitor=monitor, verbose=1, save_best_only=True, mode=mode)\n",
        "early_stop = EarlyStopping( patience=5, monitor=monitor, mode=mode)\n",
        "\n",
        "# train model\n",
        "history = model.fit(trainX, trainY.reshape(*trainY.shape, 1),\n",
        "# history = model.fit([trainX,trainY], trainY.reshape(*trainY.shape, 1),\n",
        "                    validation_data=(testX, testY.reshape(*testY.shape, 1)),\n",
        "                    # validation_data=([testX,trainY], testY.reshape(*testY.shape, 1)),\n",
        "                    epochs=EPOCHES, batch_size=BS, callbacks=[], \n",
        "                    verbose=1)\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['train','validation'])\n",
        "plt.show()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"model_22\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_29 (InputLayer)           (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_27 (Embedding)        (None, 15, 128)      1558528     input_29[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_30 (LSTM)                  [(None, 128), (None, 131584      embedding_27[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 128)          0           lstm_30[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_20 (RepeatVector) (None, 15, 128)      0           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_31 (LSTM)                  (None, 15, 128)      131584      repeat_vector_20[0][0]           \n",
            "                                                                 lstm_30[0][1]                    \n",
            "                                                                 lstm_30[0][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_20 (TimeDistri (None, 15, 13891)    1791939     lstm_31[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 3,613,635\n",
            "Trainable params: 3,613,635\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Train on 3140 samples, validate on 32 samples\n",
            "Epoch 1/500\n",
            "3140/3140 [==============================] - 10s 3ms/step - loss: 9.0097 - val_loss: 7.3085\n",
            "Epoch 2/500\n",
            "3140/3140 [==============================] - 2s 774us/step - loss: 6.0137 - val_loss: 6.0738\n",
            "Epoch 3/500\n",
            "3140/3140 [==============================] - 2s 722us/step - loss: 5.1540 - val_loss: 5.8748\n",
            "Epoch 4/500\n",
            "3140/3140 [==============================] - 2s 752us/step - loss: 4.9848 - val_loss: 5.8815\n",
            "Epoch 5/500\n",
            "3140/3140 [==============================] - 2s 776us/step - loss: 4.9156 - val_loss: 5.9286\n",
            "Epoch 6/500\n",
            "3140/3140 [==============================] - 2s 790us/step - loss: 4.8707 - val_loss: 5.9722\n",
            "Epoch 7/500\n",
            "3140/3140 [==============================] - 2s 775us/step - loss: 4.8377 - val_loss: 6.0001\n",
            "Epoch 8/500\n",
            "3140/3140 [==============================] - 2s 750us/step - loss: 4.8062 - val_loss: 6.0280\n",
            "Epoch 9/500\n",
            "3140/3140 [==============================] - 2s 762us/step - loss: 4.7828 - val_loss: 6.0513\n",
            "Epoch 10/500\n",
            "3140/3140 [==============================] - 2s 771us/step - loss: 4.7592 - val_loss: 6.0771\n",
            "Epoch 11/500\n",
            "3140/3140 [==============================] - 2s 756us/step - loss: 4.7356 - val_loss: 6.0795\n",
            "Epoch 12/500\n",
            "3140/3140 [==============================] - 2s 753us/step - loss: 4.7124 - val_loss: 6.1029\n",
            "Epoch 13/500\n",
            "3140/3140 [==============================] - 2s 774us/step - loss: 4.6908 - val_loss: 6.1424\n",
            "Epoch 14/500\n",
            "3140/3140 [==============================] - 2s 770us/step - loss: 4.6690 - val_loss: 6.1610\n",
            "Epoch 15/500\n",
            "3140/3140 [==============================] - 2s 766us/step - loss: 4.6479 - val_loss: 6.1573\n",
            "Epoch 16/500\n",
            "3140/3140 [==============================] - 2s 767us/step - loss: 4.6202 - val_loss: 6.1482\n",
            "Epoch 17/500\n",
            "3140/3140 [==============================] - 2s 760us/step - loss: 4.5789 - val_loss: 6.1488\n",
            "Epoch 18/500\n",
            "3140/3140 [==============================] - 3s 807us/step - loss: 4.5439 - val_loss: 6.1215\n",
            "Epoch 19/500\n",
            "3140/3140 [==============================] - 2s 790us/step - loss: 4.5220 - val_loss: 6.1245\n",
            "Epoch 20/500\n",
            "1280/3140 [===========>..................] - ETA: 1s - loss: 4.4605"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-89518db237e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m                     \u001b[0;31m# validation_data=([testX,trainY], testY.reshape(*testY.shape, 1)),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                     verbose=1)\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W4L0r-6Cwwg",
        "colab_type": "code",
        "outputId": "5b842fe5-2be3-497a-871b-91a45a753b65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# model = load_model('model.h5')\n",
        "preds = model_inf.predict(testX)\n",
        "preds1 = np.argmax(preds,axis=2)\n",
        "a = np.random.choice(testY.shape[0])\n",
        "preds[a], testY[a]\n",
        "convert(trn_tokenizer, preds1[a])\n",
        "print()\n",
        "convert(rus_tokenizer, testX[a])\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 ----> <sos>\n",
            "2 ---->  v _ \n",
            "\n",
            "7158 ----> космический\n",
            "7159 ----> аппарат\n",
            "7160 ----> передал\n",
            "7161 ----> сенсационные\n",
            "2677 ----> снимки\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b10853ca-3855-4c4a-8df4-a40e60c32e87",
        "id": "nTzqkY5ZtGdS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def get_word(n, tokenizer):\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "      if index == n:\n",
        "          return word\n",
        "  return None\n",
        "  \n",
        "a = np.random.choice(trn_vocab_size)\n",
        "t = []\n",
        "for e in testX[0]:\n",
        "  s = get_word(e, rus_tokenizer)\n",
        "  if s: t.append(s)\n",
        "print( ' '.join(t) )\n",
        "\n",
        "t = []\n",
        "for e in testY[0]:\n",
        "  s = get_word(e, trn_tokenizer)\n",
        "  if s: t.append(s)\n",
        "print( '#'.join(t) )"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "космический аппарат передал сенсационные снимки\n",
            "<sos># k a s m' 'i'1 ch' 'ix s k' 'ix' j' # 'a p a r a1 t # p' 'ix' r' 'i d a1 l # s' 'ix n s ax ts y o1 n n ax' jax' # s' n' 'i1 m k' 'i \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsT8avD8C-wh",
        "colab_type": "code",
        "outputId": "f180d1eb-63d1-4a51-f4a6-abc2ace5b7b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "preds_text = []\n",
        "prd = preds[:3]\n",
        "for i in prd:\n",
        "  temp = []\n",
        "  for j in range(len(i)):\n",
        "    t = get_word(i[j], trn_tokenizer)\n",
        "    if j > 0:\n",
        "      if (t == get_word(i[j-1], trn_tokenizer)) or (t == None):\n",
        "        temp.append('')\n",
        "      else:\n",
        "        temp.append(t+'#')\n",
        "    else:\n",
        "      if(t == None):\n",
        "            temp.append('')\n",
        "      else:\n",
        "              temp.append(t+'#') \n",
        "\n",
        "  preds_text.append(''.join(temp))\n",
        "\n",
        "def unpack(tensor):\n",
        "  t = []\n",
        "  for e in tensor:\n",
        "    s = get_word(e, rus_tokenizer)\n",
        "    if s: t.append(s)\n",
        "  return ' '.join(t)\n",
        "\n",
        "preds_text\n",
        "# print( list(zip((unpack(e) for e in testX[:3]), preds_text)))\n",
        "# pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})\n",
        "# pred_df.sample(15)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '', '']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgbiEv2w_W_R",
        "colab_type": "code",
        "outputId": "9c7cfd1f-deb6-4f6d-c2bc-91752b010d93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!wget http://www.manythings.org/anki/deu-eng.zip\n",
        "!unzip deu-eng.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-26 10:59:40--  http://www.manythings.org/anki/deu-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 104.24.109.196, 104.24.108.196, 2606:4700:3033::6818:6dc4, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|104.24.109.196|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7747747 (7.4M) [application/zip]\n",
            "Saving to: ‘deu-eng.zip’\n",
            "\n",
            "\rdeu-eng.zip           0%[                    ]       0  --.-KB/s               \rdeu-eng.zip          22%[===>                ]   1.64M  7.91MB/s               \rdeu-eng.zip         100%[===================>]   7.39M  24.5MB/s    in 0.3s    \n",
            "\n",
            "2020-02-26 10:59:40 (24.5 MB/s) - ‘deu-eng.zip’ saved [7747747/7747747]\n",
            "\n",
            "Archive:  deu-eng.zip\n",
            "  inflating: deu.txt                 \n",
            "  inflating: _about.txt              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IPzaHenLOFc",
        "colab_type": "code",
        "outputId": "6021ef74-a8b5-4945-db87-8a7aae352525",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import re\n",
        "import string\n",
        "from numpy import array, argmax, random, take\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Dense, LSTM, Embedding, Bidirectional, RepeatVector, TimeDistributed\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from keras import optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "\n",
        "# function to read raw text file\n",
        "def read_text(filename):\n",
        "    # open the file\n",
        "    file = open(filename, mode='rt', encoding='utf-8')\n",
        "    # read all text\n",
        "    text = file.read()\n",
        "    file.close()\n",
        "    return text\n",
        "  \n",
        "# split text into sentences\n",
        "def to_lines(text):\n",
        "    sents = text.strip().split('\\n')\n",
        "    sents = [i.split('\\t') for i in sents]\n",
        "    return sents\n",
        "\n",
        "# download data from http://www.manythings.org/anki/deu-eng.zip\n",
        "data = read_text(\"deu.txt\")\n",
        "deu_eng = to_lines(data)\n",
        "deu_eng = array(deu_eng)\n",
        "\n",
        "# use first 50,000 English-German sentence pairs\n",
        "deu_eng = deu_eng[:50000,:]\n",
        "\n",
        "# Text Pre-processing\n",
        "# Remove punctuation\n",
        "deu_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,0]]\n",
        "deu_eng[:,2] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,1]]\n",
        "deu_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,1]]\n",
        " \n",
        "# convert to lowercase\n",
        "for i in range(len(deu_eng)):\n",
        "    deu_eng[i,0] = deu_eng[i,0].lower()\n",
        "    deu_eng[i,2] = '<sos> ' + deu_eng[i,1].lower()\n",
        "    deu_eng[i,1] = '<sos> ' + deu_eng[i,1].lower()\n",
        "\n",
        "# Convert text to sequence \n",
        "# empty lists\n",
        "eng_l = []\n",
        "deu_l = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in deu_eng[:,0]:\n",
        "    eng_l.append(len(i.split()))\n",
        "\n",
        "for i in deu_eng[:,1]:\n",
        "    deu_l.append(len(i.split()))\n",
        "\n",
        "# function to build a tokenizer\n",
        "def tokenization(lines):\n",
        "    tokenizer = Tokenizer( )\n",
        "    tokenizer.fit_on_texts(lines)\n",
        "    return tokenizer\n",
        "  \n",
        "# prepare english tokenizer\n",
        "eng_tokenizer = tokenization(deu_eng[:, 0])\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "eng_length = 8\n",
        "print('English Vocabulary Size: %d' % eng_vocab_size)\n",
        "\n",
        "# prepare Deutch tokenizer\n",
        "deu_tokenizer = tokenization(deu_eng[:, 1])\n",
        "deu_vocab_size = len(deu_tokenizer.word_index) + 1\n",
        "deu_length = 8\n",
        "print('Deutch Vocabulary Size: %d' % deu_vocab_size)\n",
        "\n",
        "# encode and pad sequences\n",
        "def encode_sequences(tokenizer, length, lines, sos=False, eos=False):\n",
        "\n",
        "    # integer encode sequences\n",
        "    seq = tokenizer.texts_to_sequences(lines)\n",
        "\n",
        "    # pad sequences with 0 values\n",
        "    seq = pad_sequences(seq, maxlen=length, padding='post')\n",
        "    return seq\n",
        "  \n",
        "# model building\n",
        "# split data \n",
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(deu_eng, test_size=0.2, random_state = 12)\n",
        "\n",
        "# prepare training data\n",
        "trainX = encode_sequences(deu_tokenizer, deu_length, train[:, 1])\n",
        "trainX_ = encode_sequences(deu_tokenizer, deu_length, train[:, 2])\n",
        "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
        "\n",
        "# prepare validation data\n",
        "testX = encode_sequences(deu_tokenizer, deu_length, test[:, 1])\n",
        "testX_ = encode_sequences(deu_tokenizer, deu_length, test[:, 2])\n",
        "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English Vocabulary Size: 6345\n",
            "Deutch Vocabulary Size: 10502\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3a6K0uQ-m4K",
        "colab_type": "code",
        "outputId": "0c46729a-9f43-4c4c-f7c6-a863c85b00ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# build NMT model\n",
        "def define_model1(in_vocab, out_vocab, in_timesteps, out_timesteps, units):\n",
        "  input = x = Input(shape=(None,))\n",
        "  x = Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True)(x)\n",
        "  x, h, c = LSTM(units, return_state=True)(x)\n",
        "  x = RepeatVector(out_timesteps)(x)\n",
        "  x = LSTM(units, return_sequences=True)(x, initial_state = (h, c))\n",
        "  output = TimeDistributed(Dense(out_vocab, activation='softmax'))(x)\n",
        "  inference_model = model = Model(input, output)\n",
        "  return model, inference_model\n",
        "\n",
        "def define_model(in_vocab, out_vocab, in_timesteps, out_timesteps, units):\n",
        "   # encoder\n",
        "  encoder_inputs = Input(shape=(None,))\n",
        "  encoder_embedding = Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True)\n",
        "  encoder = encoder_embedding(encoder_inputs)\n",
        "  _, state_h, state_c = LSTM(units, return_state=True)(encoder)\n",
        "  encoder_states = [state_h, state_c]\n",
        "  # decoder\n",
        "  decoder_inputs = Input(shape=(None,))\n",
        "  decoder_embedding = Embedding(out_vocab, units, input_length=out_timesteps, mask_zero=True)\n",
        "  decoder = decoder_embedding(decoder_inputs)\n",
        "  decoder_lstm = LSTM(units, return_sequences=True, return_state=True)\n",
        "  decoder_outputs, _, _ = decoder_lstm(decoder, initial_state=encoder_states)\n",
        "  decoder_dense = Dense(out_vocab, activation='softmax')\n",
        "  decoder_outputs = decoder_dense(decoder_outputs)\n",
        "  model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "  #inference model\n",
        "  encoder_model = Model(encoder_inputs, encoder_states)\n",
        "  decoder_state_input_h = Input(shape=(units,))\n",
        "  decoder_state_input_c = Input(shape=(units,))\n",
        "  decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "  decoder_inputs_single = Input(shape=(None,))\n",
        "  decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\n",
        "  decoder_outputs, h, c = decoder_lstm(decoder_inputs_single_x, initial_state=decoder_states_inputs)\n",
        "  decoder_states = [h, c]\n",
        "  decoder_outputs = decoder_dense(decoder_outputs)\n",
        "  inference_model = Model(\n",
        "      [decoder_inputs_single] + decoder_states_inputs,\n",
        "      [decoder_outputs] + decoder_states\n",
        "  )\n",
        "  return model, inference_model\n",
        "\n",
        "model, model_inf = define_model(deu_vocab_size, eng_vocab_size, deu_length, eng_length, 512)\n",
        "model.summary()\n",
        "  \n",
        "rms = optimizers.RMSprop(lr=0.001)\n",
        "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')\n",
        "\n",
        "# train model\n",
        "filename = 'model.h1.24_jan_19'\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "# history = model.fit(trainX, trainY.reshape(*trainY.shape, 1), \n",
        "#           validation_data=(testX, testY.reshape(*testY.shape, 1)),\n",
        "#           epochs=30, batch_size=512, \n",
        "#           callbacks=[checkpoint], verbose=1)\n",
        "\n",
        "history = model.fit([trainX, trainX_], trainY.reshape(*trainY.shape, 1), \n",
        "          epochs=30, batch_size=512, \n",
        "          validation_data=([testX,testX_], testY.reshape(*testY.shape, 1)),\n",
        "          callbacks=[checkpoint], verbose=1)\n",
        "\n",
        "# plot validation loss vs training loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['train','validation'])\n",
        "plt.show()\n",
        "\n",
        "# load saved model\n",
        "model = load_model('model.h1.24_jan_19')\n",
        "\n",
        "# make predictions\n",
        "# preds = model.predict_classes(testX.reshape((testX.shape[0],testX.shape[1])))\n",
        "# preds = model.predict_classes(testX)\n",
        "\n",
        "preds_ohe = model_inf.predict(testX)\n",
        "preds = np.argmax(preds_ohe,axis=2)\n",
        "\n",
        "def get_word(n, tokenizer):\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == n:\n",
        "            return word\n",
        "    return None\n",
        "  \n",
        "# convert predictions into text (English)\n",
        "preds_text = []\n",
        "for i in preds:\n",
        "    temp = []\n",
        "    for j in range(len(i)):\n",
        "        t = get_word(i[j], eng_tokenizer)\n",
        "        if j > 0:\n",
        "            if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
        "                temp.append('')\n",
        "            else:\n",
        "                temp.append(t)\n",
        "             \n",
        "        else:\n",
        "            if(t == None):\n",
        "                temp.append('')\n",
        "            else:\n",
        "                temp.append(t)            \n",
        "        \n",
        "    preds_text.append(' '.join(temp))\n",
        "    \n",
        "pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})\n",
        "\n",
        "# display results\n",
        "pred_df.sample(15)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_22\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_32 (InputLayer)           (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_33 (InputLayer)           (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_17 (Embedding)        (None, 8, 512)       5377024     input_32[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_18 (Embedding)        (None, 8, 512)       3248640     input_33[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_23 (LSTM)                  [(None, 512), (None, 2099200     embedding_17[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm_24 (LSTM)                  [(None, 8, 512), (No 2099200     embedding_18[0][0]               \n",
            "                                                                 lstm_23[0][1]                    \n",
            "                                                                 lstm_23[0][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 8, 6345)      3254985     lstm_24[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 16,079,049\n",
            "Trainable params: 16,079,049\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "40000/40000 [==============================] - 14s 362us/step - loss: 4.6846 - val_loss: 4.1985\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 4.19853, saving model to model.h1.24_jan_19\n",
            "Epoch 2/30\n",
            "40000/40000 [==============================] - 10s 242us/step - loss: 3.9125 - val_loss: 3.7308\n",
            "\n",
            "Epoch 00002: val_loss improved from 4.19853 to 3.73081, saving model to model.h1.24_jan_19\n",
            "Epoch 3/30\n",
            "40000/40000 [==============================] - 10s 241us/step - loss: 3.5111 - val_loss: 3.4349\n",
            "\n",
            "Epoch 00003: val_loss improved from 3.73081 to 3.43492, saving model to model.h1.24_jan_19\n",
            "Epoch 4/30\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 3.1300 - val_loss: 3.1096\n",
            "\n",
            "Epoch 00004: val_loss improved from 3.43492 to 3.10958, saving model to model.h1.24_jan_19\n",
            "Epoch 5/30\n",
            "40000/40000 [==============================] - 10s 242us/step - loss: 2.7895 - val_loss: 2.8666\n",
            "\n",
            "Epoch 00005: val_loss improved from 3.10958 to 2.86659, saving model to model.h1.24_jan_19\n",
            "Epoch 6/30\n",
            "40000/40000 [==============================] - 10s 244us/step - loss: 2.4872 - val_loss: 2.6787\n",
            "\n",
            "Epoch 00006: val_loss improved from 2.86659 to 2.67873, saving model to model.h1.24_jan_19\n",
            "Epoch 7/30\n",
            "40000/40000 [==============================] - 10s 242us/step - loss: 2.2258 - val_loss: 2.4922\n",
            "\n",
            "Epoch 00007: val_loss improved from 2.67873 to 2.49219, saving model to model.h1.24_jan_19\n",
            "Epoch 8/30\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.9941 - val_loss: 2.3395\n",
            "\n",
            "Epoch 00008: val_loss improved from 2.49219 to 2.33949, saving model to model.h1.24_jan_19\n",
            "Epoch 9/30\n",
            "40000/40000 [==============================] - 10s 241us/step - loss: 1.7879 - val_loss: 2.2014\n",
            "\n",
            "Epoch 00009: val_loss improved from 2.33949 to 2.20144, saving model to model.h1.24_jan_19\n",
            "Epoch 10/30\n",
            "40000/40000 [==============================] - 10s 242us/step - loss: 1.6063 - val_loss: 2.1059\n",
            "\n",
            "Epoch 00010: val_loss improved from 2.20144 to 2.10589, saving model to model.h1.24_jan_19\n",
            "Epoch 11/30\n",
            "40000/40000 [==============================] - 10s 242us/step - loss: 1.4448 - val_loss: 2.0280\n",
            "\n",
            "Epoch 00011: val_loss improved from 2.10589 to 2.02799, saving model to model.h1.24_jan_19\n",
            "Epoch 12/30\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.3035 - val_loss: 1.9485\n",
            "\n",
            "Epoch 00012: val_loss improved from 2.02799 to 1.94852, saving model to model.h1.24_jan_19\n",
            "Epoch 13/30\n",
            "40000/40000 [==============================] - 10s 243us/step - loss: 1.1758 - val_loss: 1.8797\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.94852 to 1.87971, saving model to model.h1.24_jan_19\n",
            "Epoch 14/30\n",
            " 6656/40000 [===>..........................] - ETA: 7s - loss: 1.0145"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNxi-TKDNyIN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "c9ea4489-256b-48a6-b191-a3b24601b1cb"
      },
      "source": [
        "def get_word(n, tokenizer):\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == n:\n",
        "            return word\n",
        "    return None\n",
        "\n",
        "preds_ohe = model_inf.predict(testX)\n",
        "preds = np.argmax(preds_ohe,axis=2)\n",
        "\n",
        "# convert predictions into text (English)\n",
        "preds_text = []\n",
        "for i in preds:\n",
        "    temp = []\n",
        "    for j in range(len(i)):\n",
        "        t = get_word(i[j], eng_tokenizer)\n",
        "        if j > 0:\n",
        "            if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
        "                temp.append('')\n",
        "            else:\n",
        "                temp.append(t)\n",
        "             \n",
        "        else:\n",
        "            if(t == None):\n",
        "                temp.append('')\n",
        "            else:\n",
        "                temp.append(t)            \n",
        "        \n",
        "    preds_text.append(' '.join(temp))\n",
        "    \n",
        "pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})\n",
        "\n",
        "# display results\n",
        "pred_df.sample(15)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actual</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7535</th>\n",
              "      <td>something seems wrong</td>\n",
              "      <td>something seems wrong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7910</th>\n",
              "      <td>i sell computers</td>\n",
              "      <td>i sell computer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3590</th>\n",
              "      <td>youre too inflexible</td>\n",
              "      <td>youre too inflexible</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1534</th>\n",
              "      <td>youre not dressed</td>\n",
              "      <td>youre not dressed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2444</th>\n",
              "      <td>the baby is screaming</td>\n",
              "      <td>the baby is in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8949</th>\n",
              "      <td>youre a coward</td>\n",
              "      <td>youre a coward</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5977</th>\n",
              "      <td>you look very pale</td>\n",
              "      <td>you look very pale</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8768</th>\n",
              "      <td>no kidding</td>\n",
              "      <td>seriously</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2450</th>\n",
              "      <td>are we ready for it</td>\n",
              "      <td>are we ready to that</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4583</th>\n",
              "      <td>i cant find my pen</td>\n",
              "      <td>i cant find my car</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>873</th>\n",
              "      <td>everybody knows</td>\n",
              "      <td>everyone knows</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9869</th>\n",
              "      <td>who brought this</td>\n",
              "      <td>who made this</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1447</th>\n",
              "      <td>take a look at that</td>\n",
              "      <td>look at that</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5791</th>\n",
              "      <td>thats broken</td>\n",
              "      <td>that wont working</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6041</th>\n",
              "      <td>why are you so sad</td>\n",
              "      <td>why are you so sad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     actual                   predicted\n",
              "7535  something seems wrong  something seems wrong     \n",
              "7910       i sell computers        i sell computer     \n",
              "3590   youre too inflexible   youre too inflexible     \n",
              "1534      youre not dressed      youre not dressed     \n",
              "2444  the baby is screaming          the baby is in    \n",
              "8949         youre a coward         youre a coward     \n",
              "5977     you look very pale      you look very pale    \n",
              "8768             no kidding            seriously       \n",
              "2450    are we ready for it     are we ready to that   \n",
              "4583     i cant find my pen       i cant find my car   \n",
              "873         everybody knows        everyone knows      \n",
              "9869       who brought this          who made this     \n",
              "1447    take a look at that           look at that     \n",
              "5791           thats broken      that wont working     \n",
              "6041     why are you so sad       why are you so sad   "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTpyAZQWGZ3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate_sentence(input_seq):\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = word2idx_outputs['<sos>']\n",
        "    eos = word2idx_outputs['<eos>']\n",
        "    output_sentence = []\n",
        "\n",
        "    for _ in range(max_out_len):\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "        idx = np.argmax(output_tokens[0, 0, :])\n",
        "\n",
        "        if eos == idx:\n",
        "            break\n",
        "\n",
        "        word = ''\n",
        "\n",
        "        if idx > 0:\n",
        "            word = trn_tokenizer.index_word[idx]\n",
        "            output_sentence.append(word)\n",
        "\n",
        "        target_seq[0, 0] = idx\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return ' '.join(output_sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrkDmXxDP6My",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "97d312ae-c843-4317-cd02-a648564b0a33"
      },
      "source": [
        "import numpy as np\n",
        "i = np.random.choice(len(trainX))\n",
        "input_seq = trainX[i:i+1]\n",
        "translation = translate_sentence(input_seq)\n",
        "print('-')\n",
        "print('Input:', input_sentences[i])\n",
        "print('Response:', translation)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-4bd0af56169c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minput_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtranslation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-62c089b4858d>\u001b[0m in \u001b[0;36mtranslate_sentence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mstates_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtarget_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtarget_seq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2idx_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<sos>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0meos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2idx_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<eos>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0moutput_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'word2idx_outputs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORw-FSMFQLvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}